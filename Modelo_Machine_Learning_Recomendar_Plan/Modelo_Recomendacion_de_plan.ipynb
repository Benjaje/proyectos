{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 7 Creacion de un Modelo que pueda analizar el comportamiento de los clientes y recomendar uno de los nuevos planes de Megaline: Smart o Ultra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción \n",
    "Utilizaremos el conjunto de datos `/datasets/users_behavior.csv` para poder entrenar un modelo que recomiende a los clientes el mejor plan para ellos con base a su historial. Para lograr esto llevaremos a cabo las siguientes etapas en el orden que se describen.\n",
    "\n",
    "### Etapas\n",
    "1. Importaremos las librerias y abriremos y examinaremos el archivo de datos.\n",
    "    * 1.1 Importar Librerias\n",
    "    * 1.2 Abrir archivo de datos y examinarlo.\n",
    "2. Segmentaremos los datos fuente en un conjunto de entrenamiento, uno de validación y uno de prueba.\n",
    "3. Investigaremos la calidad de diferentes modelos cambiando los hiperparámetros. Describiremos brevemente los hallazgos del estudio.\n",
    "    * 3.1 Modelo Árbol de decisión de regresión\n",
    "    * 3.2 Modelo Bosque aleatorio de regresión\n",
    "    * 3.3 Modelo Regresión lineal\n",
    "4. Comprobaremos la calidad del modelo usando el conjunto de prueba.\n",
    "5. Prueba de cordura al modelo\n",
    "6. Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 1 Importacion de librerias y examinacion del archivo de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1  Importar Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaremos la libreria pandas y los modelos necesarios para poder crear nuestros modelos.\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Abrir archivo de datos y examinarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numero de valores duplicados: 0\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "display(df.head(5))\n",
    "print('\\nNumero de valores duplicados:',df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBSERVACIONES**\n",
    "Nuestro conjunto de datos esta listo para poder llevar a cabo la creación de modelos ya que no tenemos valores faltantes ni duplicados. La columna `calls` contiene el numero de llamadas, la columna `minutes` contiene la duración de las llamadas en minutos, la columna `messages` contiene el numero de mensajes de texto, la columna `mb_used` contiene la cantidad de megas usados y la columna `is_ultra` es una columna binario de zeros y unos donde el 0 representa que tiene el plan `Smart` y el 1 representa que tienen el plan `Ultra`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 2 Segmentacion de los datos fuente en un conjunto de entrenamiento, uno de validación y uno de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos features y target\n",
    "\n",
    "features = df.drop(['is_ultra'], axis = 1)\n",
    "target = df['is_ultra']\n",
    "\n",
    "# Primero dividimos nuestro conjunto de datos en 60% para el entrenamiento, 20 para el conjunto de validacion\n",
    "# 20 para el conjunto de prueba.\n",
    "\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features, \n",
    "target, test_size= .4 , random_state=12345)\n",
    "\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_valid, \n",
    "target_valid, test_size= .50 , random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "para dividir nuestro conjunto de datos utilizamos `train_test_split` El cual nos permite dividir nuestro conjunto de datos en 2 porciones y esas porciones se basaran en el porcentaje que nosotros indiquemos en `test_size`. Usualmente, el tamaño del conjunto de validación y del de prueba son iguales. Lo que nos da una proporción de datos fuente de 3:1:1 y esto seria una proporcion de 60% de los datos para el conjunto de entrenamiento y `20%` para el conjunto de validacion y `20%` para el conjunto de prueba. Para lograr esto dividimos el conjunto de datos de tal forma que el conjunto de entrenamiento se quede con el 60 porciento y el conjunto de validacion con un 40 porciento para despues dividirlo en la mitad y que el conjunto de prueba tenga un 20 porciento al igual que el conjunto de validacion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 3 Investigaremos la calidad de diferentes modelos cambiando los hiperparámetros. Describiremos brevemente los hallazgos del estudio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Modelo Árbol de decisión de regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umbral de exactitud del mejor modelo con el conjunto de validación (max_depth = 3): 0.7853810264385692\n"
     ]
    }
   ],
   "source": [
    "# Identificaremos los mejores hiperparamtros para nuestro modelo de Arbol de decision de regresion.\n",
    "\n",
    "best_model = None\n",
    "best_result = 0 \n",
    "best_depth = 0\n",
    "for depth in range(1, 6): # seleccionaremos el rango del hiperparámetro\n",
    "    model = DecisionTreeClassifier(max_depth = depth, random_state = 12345)\n",
    "    model.fit(features_train, target_train) # entrenaremos el modelo con el conjunto de entrenamiento\n",
    "    predictions_valid = model.predict(features_valid) \n",
    "    result =  accuracy_score(target_valid, predictions_valid)\n",
    "    if result > best_result:\n",
    "        best_model = model\n",
    "        best_result = result\n",
    "        best_depth = depth\n",
    "\n",
    "print(f\"Umbral de exactitud del mejor modelo con el conjunto de validación (max_depth = {best_depth}): {best_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder decidir cual seria la mejor profundidad de nuestro modelo de Arbol utilizamos for para que tomara un rango entre 1 y 5 ya que si aumentamos nuestro rango no vemos una mejora significativa en el resultado y solo haria el proceso mas lento por lo cual decidimos optar por ese rango de profundidad. Al hacer esto recibimos como respuesta que la mejor profundidad es 3 y el mejor resultado que nos da es un 78.5% de exactitud lo cual no esta nada mal ya que supera nuestro umbral de exactitud establecido en un 75%, seguiremos probrando los demas modelos para ver si existe uno que nos de una mejor exactitud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3.2 Modelo Bosque aleatorio de regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umbral de exactitud del mejor modelo con el conjunto de validación 0.8087091757387247 n_estimators: 40 best_depth: 9\n"
     ]
    }
   ],
   "source": [
    "# Crearemos nuestro Modelo Bosque aleatorio de regresion\n",
    "\n",
    "best_model_rf = None\n",
    "best_result = 0\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "for est in range(10, 51, 10):\n",
    "    for depth in range (1, 10):\n",
    "        model = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)\n",
    "        model.fit(features_train, target_train) # entrenaremos el modelo con el conjunto de entrenamiento\n",
    "        predictions_valid = model.predict(features_valid) # obténdremos las predicciones del modelo con el conjunto de validación\n",
    "        result = accuracy_score(target_valid, predictions_valid) \n",
    "        if result > best_result:\n",
    "            best_model_rf = model\n",
    "            best_result = result\n",
    "            best_est = est\n",
    "            best_depth = depth\n",
    "\n",
    "print(\"Umbral de exactitud del mejor modelo con el conjunto de validación\", best_result, \"n_estimators:\", best_est, \"best_depth:\", depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow este modelo tiene una exactitud del 80.8% es superior al del modelo anterior por lo que podemos descartar al modelo anterior. En este caso estamos probando un modelo de bosque y utilizamos for para poner un rango de de 10 a 50, en intervalos de 10 y esto lo usamos para poder decidir cual seria la mejor cantidad de arboles que nosotros seleccionamos con n_estimators por lo cual n debe de estar en ese rango que acabamos de definir y utilizamos ese rango debido a que si aumentamos el rango no vemos una diferencia significativa. Tambien utilizamos for para poder descubrir cual es el mejor rango de profundidad entre 1 y 10 y de la misma forma que explicamos si utilizamos un rango mas grande no vemos una diferencia significativa y es por eso que dejamos ese rango. Al recibir nuestra respuesta tenemos un umbral de exactitud del `80.8%`, obtenemos que la mejor cantidad de arboles son 40 con una profundidad de 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Modelo Regresión logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umbral de exactitud del modelo de regresión logistica en el conjunto de validación: 0.7107309486780715\n"
     ]
    }
   ],
   "source": [
    "#Crearemos nuestro Modelo de Regresion lineal\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(features_train, target_train) # entrenaremos el modelo con el conjunto de entrenamiento\n",
    "predictions_valid = model.predict(features_valid) # obténdremos las predicciones del modelo con el conjunto de validación\n",
    "\n",
    "result = accuracy_score(target_valid, predictions_valid)\n",
    "print( \"Umbral de exactitud del modelo de regresión logistica en el conjunto de validación:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro modelo de Regresion Logistica obtuve el porcentaje mas bajo de exactitud con un `71%` por lo cual tambien lo descartaremos y optaremos por usar el modelo de bosque."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 4 Comprobaremos la calidad del mejor modelo usando el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7962674961119751\n"
     ]
    }
   ],
   "source": [
    "# utilizaremos el modelo bosque aleatorio de regresion con el conjunto de prueba\n",
    "\n",
    "predictions_test = best_model_rf.predict(features_test) \n",
    "result =  accuracy_score(target_test, predictions_test)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al utilizar el conjunto de prueba con nuestro mejor modelo que habiamos guardado en la variable `best_model_rf` que representa el modelo de bosque aleatorio de regresion obtenemos un `79.6%` de exactitud el cual supera el `75%` de umbral de exatitud que se nos requeria. EL porcentaje de exactitud bajo un poco con el conjunto de prueba pero es normal que eso pase y aun asi sigue superando el umbral de exatitud de los modelos de `arbol` y `linear`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 5 Comprobaremos la cordura del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del Dummy Classifier: 0.6842923794712286\n",
      "Exactitud del Mejor Modelo: 0.7962674961119751\n"
     ]
    }
   ],
   "source": [
    "# Crearemos un modelo DummyClassifier para poder hacer la prueba de cordura del modelo.\n",
    "dummy_model = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "\n",
    "dummy_model.fit(features_train, target_train) # entrenaremos el modelo con el conjunto de entrenamiento.\n",
    "\n",
    "predictions_dummy = dummy_model.predict(features_test) # obtendremos las predicciones con el conjunto de prueba.\n",
    "\n",
    "predictions_best_model = best_model_rf.predict(features_test) # obtener las predicciones del mejor modelo con el mismo conjunto.\n",
    "\n",
    "# Comparar la exacitud de los modelos.\n",
    "accuracy_dummy = accuracy_score(target_test, predictions_dummy)\n",
    "accuracy_best_model = accuracy_score(target_test, predictions_best_model)\n",
    "\n",
    "# Imprimir las exactitudes\n",
    "print(\"Exactitud del Dummy Classifier:\", accuracy_dummy)\n",
    "print(\"Exactitud del Mejor Modelo:\", accuracy_best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro mejor modelo supera de una manera significativa el modelo DummyClassifier, lo cual nos dice que nuestro modelo si funciona y es una mejor opcion que simplemente adoptar una estrategia simple. Nuestro modelo tiene un buen porcentaje de exactitud y es capaz de aprender de los patrones que se hallan en los datos y tiene la capacidad de hacer predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 6 Conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algo que aprendi en este proyecto es que siempre va a ser muy bueno dividir la carga de trabajo del proyecto en partes pequeñas. En este caso pudimos enfocarnos solamente en crear los modelos y compararlos, fue mucho mas eficaz que tener todo el trabajo de limpiar los datos y todo eso y quizas nuestra mente no se enfocaria de la mejor forma, pero al dividir el trabajo en partes todo es mas facil. De este analisis me gustaria destacar 3 puntos principales.\n",
    "\n",
    "1. La exactitud de nuestro modelo es del 80.8% con nuestro conjunto de entrenamiento y 79.6% con nuestro conjunto de prueba con lo cual ambos superan la meta establecida de un 75% de exactitud.\n",
    "\n",
    "\n",
    "2. El mejor modelo es un Bosque aleatorio de regresion con 40 arboles y 9 de profundidad.\n",
    "\n",
    "\n",
    "3. Nuestro modelo supera de forma significativa al modelo Dummy por lo cual nuestro modelo si funciona y es util ya que tiene mejor desempeño que optar por una estrategia simple."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
