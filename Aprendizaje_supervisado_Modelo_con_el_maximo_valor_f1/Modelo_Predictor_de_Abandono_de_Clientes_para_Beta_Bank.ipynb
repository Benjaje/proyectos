{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creacion de Modelo con el maximo valor f1 posible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "Utilizaremos el conjunto de datos `/datasets/Churn.csv` para crear un modelo con el maximo valor f1 posible, tambien mediremos la métrica AUC-ROC y la compararemos con el valor F1. Para esto llevaremos a cabo las siguientes etapas.\n",
    "\n",
    "### Etapas\n",
    "1. Importaremos las librerias y prepararemos los datos.\n",
    "   * 1.1 Importaremos las librerias.\n",
    "   * 1.2 Leeremos y prepararemos los datos.\n",
    "2. Procesar todos los tipos de caracteristicas\n",
    "3. Examinaremos el equilibrio de clases y entrenaremos el modelo sin tener en cuenta el desequilibrio.\n",
    "    * 2.2 Entrenar modelos sin tomar en cuenta el desequilibrio\n",
    "    * 2.3 Examinar el equilibrio\n",
    "4. Mejoraremos la Calidad del modelo.\n",
    "    * 4.1 Sobremuestreo\n",
    "    * 4.2 Submuestreo\n",
    "5. Examinaremos los valores AUC-ROC\n",
    "6. Realizaremos la prueba final.\n",
    "7. Escribiremos un conclusion general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importaremos las librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OrdinalEncoder \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leeremos y prepararemos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n",
      "\n",
      "Numero de valores duplicados: 0\n"
     ]
    }
   ],
   "source": [
    "data.info()\n",
    "data = data.dropna(subset=['Tenure'])\n",
    "print('\\nNumero de valores duplicados:',data.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42     2.0       0.00              1   \n",
       "1          608     Spain  Female   41     1.0   83807.86              1   \n",
       "2          502    France  Female   42     8.0  159660.80              3   \n",
       "3          699    France  Female   39     1.0       0.00              2   \n",
       "4          850     Spain  Female   43     2.0  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Eliminacion de columnas inecesarias\n",
    "data_s = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "display(data_s.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBSERVACIONES**\n",
    "Nuestro conjunto de datos esta listo para poder llevar a cabo la creación de modelos ya que no tenemos valores faltantes ni duplicados. Al principio el conjunto de datos tenia datos faltantes en la columna `Tenure` pero debido a que eran una cantidad muy pequeña obtamos por eliminarlos. Tambien eliminaremos las columnas `RowNumber, Customerid y Surname` ya que son irrelevantes para nuestro modelo y solo harian el proceso mas lento ya que Surname al ser una columna categorica si usaramos OHE con esta columna crearia muchas columnas inecesarias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesar todos los tipos de caracteristicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En nuestro conjunto de datos tenemos columnas con datos categoricos que necesitan ser cambiadas a variables binarias, para lograrlo usaremos OHE(One-Hot-Encoding) en todo el conjunto de datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42     2.0       0.00              1          1   \n",
       "1          608   41     1.0   83807.86              1          0   \n",
       "2          502   42     8.0  159660.80              3          1   \n",
       "3          699   39     1.0       0.00              2          0   \n",
       "4          850   43     2.0  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0               1        101348.88       1                  0   \n",
       "1               1        112542.58       0                  0   \n",
       "2               0        113931.57       1                  0   \n",
       "3               0         93826.63       0                  0   \n",
       "4               1         79084.10       0                  0   \n",
       "\n",
       "   Geography_Spain  Gender_Male  \n",
       "0                0            0  \n",
       "1                1            0  \n",
       "2                0            0  \n",
       "3                0            0  \n",
       "4                1            0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertimos los valores categoricos a binarios\n",
    "data_ohe = pd.get_dummies(data_s, drop_first=True)\n",
    "data_ohe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora dividiremos nuestro conjunto de datos en 3 partes, El primer conjunto sera el de entrenamiento con un 60 porciente, el segundo conjunto sera para el de validacion con 20 y por ultimo sera el conjunto de prueba con el 20 porciento faltante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero dividimos nuestro conjunto de datos en 60% para el entrenamiento, 20 para el conjunto de validacion\n",
    "# 20 para el conjunto de prueba.\n",
    "\n",
    "features = data_ohe.drop(['Exited'], axis = 1)\n",
    "target = data_ohe['Exited']\n",
    "\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features, \n",
    "target, test_size= .4 , random_state=12345)\n",
    "\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_valid, \n",
    "target_valid, test_size= .50 , random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora estandarizaremos las características numéricas con StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train)\n",
    "\n",
    "features_train  = scaler.transform(features_train)\n",
    "features_valid = scaler.transform(features_valid)\n",
    "features_test = scaler.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examinaremos el equilibrio de clases y entrenaremos el modelo sin tener en cuenta el desequilibrio.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenaremos los modelos sin tomar en cuenta el desequilibrio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 del mejor modelo con el conjunto de validación (max_depth = 4): 0.5414551607445008\n"
     ]
    }
   ],
   "source": [
    "# Modelo Arbol de Decision\n",
    "best_model_td = None\n",
    "best_result = 0 \n",
    "best_depth = 0\n",
    "for depth in range(1, 6): # seleccionaremos el rango del hiperparámetro\n",
    "    model = DecisionTreeClassifier(max_depth = depth, random_state = 12345)\n",
    "    model.fit(features_train, target_train) # entrenaremos el modelo con el conjunto de entrenamiento\n",
    "    predictions_valid = model.predict(features_valid) \n",
    "    result =  f1_score(target_valid, predictions_valid)\n",
    "    if result > best_result:\n",
    "        best_model_td = model\n",
    "        best_result = result\n",
    "        best_depth = depth\n",
    "\n",
    "print(f\"f1 del mejor modelo con el conjunto de validación (max_depth = {best_depth}): {best_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 del mejor modelo con el conjunto de validación 0.5758620689655172 n_estimators: 20 best_depth: 9\n"
     ]
    }
   ],
   "source": [
    "# Crearemos nuestro Modelo Bosque aleatorio de regresion\n",
    "\n",
    "best_model_rf = None\n",
    "best_result = 0\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "for est in range(10, 51, 10):\n",
    "    for depth in range (1, 10):\n",
    "        model = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)\n",
    "        model.fit(features_train, target_train) # entrenaremos el modelo con el conjunto de entrenamiento\n",
    "        predictions_valid = model.predict(features_valid) # obténdremos las predicciones del modelo con el conjunto de validación\n",
    "        result = f1_score(target_valid, predictions_valid) \n",
    "        if result > best_result:\n",
    "            best_model_rf = model\n",
    "            best_result = result\n",
    "            best_est = est\n",
    "            best_depth = depth\n",
    "\n",
    "print(\"f1 del mejor modelo con el conjunto de validación\", best_result, \"n_estimators:\", best_est, \"best_depth:\", depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3033932135728543\n"
     ]
    }
   ],
   "source": [
    "# Modelo Regresion Logistica\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "result = f1_score(target_valid, predicted_valid)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ninguno de nuestros modelos logra alcanzar el objetivo de tener un calificacion de f1 minima de .59, nuestro modelo mas cercano fue el del `bosque aleatorio` con un `.57` despues el `arbol de decicion` con `.54` y en ultimo lugar el modelo de Regresion Logistica con `0.30`. En la siguiente seccion haremos las modificaciones necesarias para obtener una puntuacion minima de 0.59, muy probablemente el modelo de bosque aleatorio tendra un mejor resultado con nuestras modificaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examinacion del equilibrio de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89      1441\n",
      "           1       0.61      0.20      0.30       377\n",
      "\n",
      "    accuracy                           0.81      1818\n",
      "   macro avg       0.72      0.58      0.60      1818\n",
      "weighted avg       0.78      0.81      0.77      1818\n",
      "\n"
     ]
    }
   ],
   "source": [
    " equilibrio = classification_report(target_valid, predicted_valid)\n",
    "print(equilibrio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro modelo es bueno para predecir zeros pero es malo para predecir unos y eso tiene sentido, en la columna support podemos ver que tenemos muchos mas datos para los zeros que para los unos, asi que podemos ver que tenemos una buen precision y recall en los zeros por lo tanto tenemos una buena calificacion f1 para los zeros, pero debido a que en los unos tenemos menos datos, eso hace que tengamos una calificacion baja en la precision, en el recall y en la calificacion f1. Para solucionar esto aumentaremos los unos para que tengan una proporcion similar a los zeros y ayude a que mejore la calificacion. Lo que significaria que nuestro modelo seria mejor para predecir unos que es donde le hace falta mejorar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mejoraremos la Calidad del Modelo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iniciaremos con un sobremuestreo para cada modelo con las clases balanceadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    5630\n",
      "0    4328\n",
      "Name: Exited, dtype: int64\n",
      "\n",
      "F1: 0.4859211584875302\n"
     ]
    }
   ],
   "source": [
    "# Aplicar sobremuestreo\n",
    "\n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = pd.DataFrame(features[target == 0])\n",
    "    features_ones = pd.DataFrame(features[target == 1])\n",
    "    target_zeros = pd.Series(target[target == 0])\n",
    "    target_ones = pd.Series(target[target == 1])\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345\n",
    "    )\n",
    "\n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(\n",
    "    features_train, target_train, 5\n",
    ")\n",
    "print(target_upsampled.value_counts())\n",
    "\n",
    "model = LogisticRegression(random_state = 12345, solver = 'liblinear')\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "\n",
    "print('\\nF1:', f1_score(target_valid, predicted_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 con sobremuestreo del mejor modelo con el conjunto de validación (max_depth = 5): 0.5735449735449736\n"
     ]
    }
   ],
   "source": [
    "# Modelo Arbol de Decision\n",
    "best_model_sob = None\n",
    "best_result = 0 \n",
    "best_depth = 0\n",
    "for depth in range(1, 6): # seleccionaremos el rango del hiperparámetro\n",
    "    model = DecisionTreeClassifier(max_depth = depth, random_state = 12345, class_weight = 'balanced')\n",
    "    model.fit(features_upsampled, target_upsampled)\n",
    "    predictions_valid = model.predict(features_valid) \n",
    "    result =  f1_score(target_valid, predictions_valid)\n",
    "    if result > best_result:\n",
    "        best_model_sob = model\n",
    "        best_result = result\n",
    "        best_depth = depth\n",
    "\n",
    "print(f\"f1 con sobremuestreo del mejor modelo con el conjunto de validación (max_depth = {best_depth}): {best_result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 con sobremuestreo del mejor modelo con el conjunto de validación 0.641291810841984 n_estimators: 100 best_depth: 9\n"
     ]
    }
   ],
   "source": [
    "best_model_rf_sob = None\n",
    "best_result = 0\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "for est in range(10, 101, 10):\n",
    "    for depth in range (1, 10):\n",
    "        model = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth, class_weight = 'balanced')\n",
    "        model.fit(features_upsampled, target_upsampled)\n",
    "        predictions_valid = model.predict(features_valid) # obténdremos las predicciones del modelo con el conjunto de validación\n",
    "        result = f1_score(target_valid, predictions_valid) \n",
    "        if result > best_result:\n",
    "            best_model_rf_sob = model\n",
    "            best_result = result\n",
    "            best_est = est\n",
    "            best_depth = depth\n",
    "\n",
    "print(\"f1 con sobremuestreo del mejor modelo con el conjunto de validación\", best_result, \"n_estimators:\", best_est, \"best_depth:\", depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al realizar el sobremuestreo y aplicarlo en cada uno de nuestros modelos, vemos claramente que ha aumentado la calificacion f1 en todos nuestros modelos. Lo que hizimos fue ver la diferencia que existian entre los zeros y unos y aumentamos los unos ya que aparecian mucho menos que los zeros. Para poder saber por cual numero teniamos que multiplicar los unos solo imprimiamos `print(target_upsampled.value_counts())` y modificabamos el numero que nos aproximara mas la cantidad de zeros y unos. Hacer esto ayudo mucho al modelo a predecir mejor los unos ya que le damos una mayor cantidad de unos que el pueda usar para entrenarse. Podemos destacar que el modelo `best_model_rf_sob` obtuvo una calificacion de `0.64` siendo superior a nuestra meta de `0.59` por lo cual este es nuetro mejor modelo con el mejor conjunto de datos de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora haremos un Submuestreo para cada modelo con las clases balanceadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1298\n",
      "1    1126\n",
      "Name: Exited, dtype: int64\n",
      "\n",
      "F1: 0.5059578368469294\n"
     ]
    }
   ],
   "source": [
    "def downsample(features, target, fraction):\n",
    "    features_zeros = pd.DataFrame(features[target == 0])\n",
    "    features_ones = pd.DataFrame(features[target == 1])\n",
    "    target_zeros = pd.Series(target[target == 0])\n",
    "    target_ones = pd.Series(target[target == 1])\n",
    "\n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=12345)]\n",
    "        + [features_ones]\n",
    "    )\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=12345)]\n",
    "        + [target_ones]\n",
    "    )\n",
    "\n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=12345\n",
    "    )\n",
    "\n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "\n",
    "features_downsampled, target_downsampled = downsample(\n",
    "    features_train, target_train, 0.30)\n",
    "print(target_downsampled.value_counts())\n",
    "model = LogisticRegression(random_state = 12345, solver = 'liblinear', class_weight = 'balanced')\n",
    "model.fit(features_downsampled, target_downsampled)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "\n",
    "print('\\nF1:', f1_score(target_valid, predicted_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 con subremuestreo del mejor modelo con el conjunto de validación (max_depth = 5): 0.5632730732635585\n"
     ]
    }
   ],
   "source": [
    "best_model_sub = None\n",
    "best_result = 0 \n",
    "best_depth = 0\n",
    "for depth in range(1, 6): # seleccionaremos el rango del hiperparámetro\n",
    "    model = DecisionTreeClassifier(max_depth = depth, random_state = 12345, class_weight = 'balanced')\n",
    "    model.fit(features_downsampled, target_downsampled)\n",
    "    predictions_valid = model.predict(features_valid) \n",
    "    result =  f1_score(target_valid, predictions_valid)\n",
    "    if result > best_result:\n",
    "        best_model_sub = model\n",
    "        best_result = result\n",
    "        best_depth = depth\n",
    "\n",
    "print(f\"f1 con subremuestreo del mejor modelo con el conjunto de validación (max_depth = {best_depth}): {best_result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 con subremuestreo del mejor modelo con el conjunto de validación 0.6078838174273858 n_estimators: 60 best_depth: 9\n"
     ]
    }
   ],
   "source": [
    "best_model_rf_sub = None\n",
    "best_result = 0\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "for est in range(10, 101, 10):\n",
    "    for depth in range (1, 10):\n",
    "        model = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth, class_weight = 'balanced')\n",
    "        model.fit(features_downsampled, target_downsampled)\n",
    "        predictions_valid = model.predict(features_valid) # obténdremos las predicciones del modelo con el conjunto de validación\n",
    "        result = f1_score(target_valid, predictions_valid) \n",
    "        if result > best_result:\n",
    "            best_model_rf_sub = model\n",
    "            best_result = result\n",
    "            best_est = est\n",
    "            best_depth = depth\n",
    "\n",
    "print(\"f1 con subremuestreo del mejor modelo con el conjunto de validación\", best_result, \"n_estimators:\", best_est, \"best_depth:\", depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que hizimos en este submuestreo fue dividir la cantidad de zeros que teniamos en nuestro conjunto de datos para que fuera una cantidad similar a la de los unos que teniamos para de esta forma poder ayudar a que nuestro modelo pudiera mejorar en la prediccion de zeros. Tanto el sobremuestreo como el submuestreo funcionan para hacer que la cantidad de zeros y unos en nuestro conjunto de datos en nuestro objetivo sean similares para que ayuden a nuestro modelos a tener mejores predicciones al estar mas equilibrado. Para poder saber que tan desquilibrados estaban y saber por cual numero teniamos que dividir solo imprimiamos `target_downsampled.value_counts()` y modificabamos el numero que representaba la fraccion para que los zeros disminuyeran y fueran una cantidad similar a los unos. Nuestro mejor modelo fue de igual manera el bosque aleatorio con una calificacion de `.60` superando nuestra meta pero al tener una mejor calificacion nuestro modelo anterior con la tecnica del sobremuestro nos quedaremos por lo tanto con nuestro modelo anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examinaremos los valores AUC-ROC de nuestro mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8683477617407598\n"
     ]
    }
   ],
   "source": [
    "last_model = best_model_rf_sob\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print(auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro valor AUC-ROC nos da un valor de `0.86` muy superior a 0.5 lo que significa que nuestro modelo distingue muy bien los valores positivos y negativmos, mejor que un clasificador aleatorio, por lo tanto nuestro modelo si funciona."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realizaremos la prueba final con nuestro mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.602905569007264\n"
     ]
    }
   ],
   "source": [
    "# utilizaremos nuestro mejor modelo de bosque aleatorio de regresion con el conjunto de prueba\n",
    "\n",
    "predictions_test = last_model.predict(features_test) \n",
    "result =  f1_score(target_test, predictions_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro modelo supero la prueba al tener una calificacion f1 de `.60` con el conjunto de prueba, lo cual es una muy buena señal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion general\n",
    "En este proyecto utilizamos diferentes funciones que ayudaron a mejorar la calidad de los datos que ingresabamos a nuestros modelos, lo cual mejoro de forma significativa las predicciones de nuestro modelo. Me gustaria destacar 3 puntos principales de este proyecto.\n",
    "\n",
    "1. Nuestro mejor modelo de este proyecto es `best_model_rf_sob` con una calificacion f1 de `0.64` con Sobremuestreo y una calificacion f1 con nuestro conjunto de prueba de `0.60`\n",
    "2. El sobremuestreo y submuestreo son dos tecnicas que nos ayudan a poder equilibrar las clases.\n",
    "3. Y los valores AUC-ROC nos ayudan a determinar si nuestro modelo clasifica mejor los valores positivos y negativos que un simple clasificador aleatorio al tener un valor superior a `0.5`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
