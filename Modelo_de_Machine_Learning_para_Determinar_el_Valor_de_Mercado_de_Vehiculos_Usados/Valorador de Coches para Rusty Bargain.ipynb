{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El servicio de venta de autos usados Rusty Bargain está desarrollando una aplicación para atraer nuevos clientes. Gracias a esa app, puedes averiguar rápidamente el valor de mercado de tu coche. Tienes acceso al historial: especificaciones técnicas, versiones de equipamiento y precios. Tienes que crear un modelo que determine el valor de mercado.\n",
    "A Rusty Bargain le interesa:\n",
    "- la calidad de la predicción;\n",
    "- la velocidad de la predicción;\n",
    "- el tiempo requerido para el entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapas del proyecto \n",
    "\n",
    "1. Importaremos las librerias y prepararemos los datos.\n",
    "   * 1.1 Importaremos las librerias.\n",
    "   * 1.2 Leeremos y revisaremos los datos.\n",
    "2. Limpiaremos  y prepararemos los datos para entrenar los modelos.\n",
    "   * 2.1 Limpieza de Datos\n",
    "   * 2.2 Preparación de Datos.\n",
    "3. Entrenar modelos.\n",
    "4. Analisis de los 3 mejores modelos .\n",
    "5. Conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Importación de Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import lightgbm as lgb\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Leeremos y Revisaremos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/car_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 354369 entries, 0 to 354368\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   DateCrawled        354369 non-null  object\n",
      " 1   Price              354369 non-null  int64 \n",
      " 2   VehicleType        316879 non-null  object\n",
      " 3   RegistrationYear   354369 non-null  int64 \n",
      " 4   Gearbox            334536 non-null  object\n",
      " 5   Power              354369 non-null  int64 \n",
      " 6   Model              334664 non-null  object\n",
      " 7   Mileage            354369 non-null  int64 \n",
      " 8   RegistrationMonth  354369 non-null  int64 \n",
      " 9   FuelType           321474 non-null  object\n",
      " 10  Brand              354369 non-null  object\n",
      " 11  NotRepaired        283215 non-null  object\n",
      " 12  DateCreated        354369 non-null  object\n",
      " 13  NumberOfPictures   354369 non-null  int64 \n",
      " 14  PostalCode         354369 non-null  int64 \n",
      " 15  LastSeen           354369 non-null  object\n",
      "dtypes: int64(7), object(9)\n",
      "memory usage: 43.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>vehicletype</th>\n",
       "      <th>registrationyear</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>power</th>\n",
       "      <th>model</th>\n",
       "      <th>mileage</th>\n",
       "      <th>fueltype</th>\n",
       "      <th>brand</th>\n",
       "      <th>notrepaired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993</td>\n",
       "      <td>manual</td>\n",
       "      <td>0</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18300</td>\n",
       "      <td>coupe</td>\n",
       "      <td>2011</td>\n",
       "      <td>manual</td>\n",
       "      <td>190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125000</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>audi</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9800</td>\n",
       "      <td>suv</td>\n",
       "      <td>2004</td>\n",
       "      <td>auto</td>\n",
       "      <td>163</td>\n",
       "      <td>grand</td>\n",
       "      <td>125000</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>jeep</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1500</td>\n",
       "      <td>small</td>\n",
       "      <td>2001</td>\n",
       "      <td>manual</td>\n",
       "      <td>75</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3600</td>\n",
       "      <td>small</td>\n",
       "      <td>2008</td>\n",
       "      <td>manual</td>\n",
       "      <td>69</td>\n",
       "      <td>fabia</td>\n",
       "      <td>90000</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>skoda</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price vehicletype  registrationyear gearbox  power  model  mileage  \\\n",
       "0    480         NaN              1993  manual      0   golf   150000   \n",
       "1  18300       coupe              2011  manual    190    NaN   125000   \n",
       "2   9800         suv              2004    auto    163  grand   125000   \n",
       "3   1500       small              2001  manual     75   golf   150000   \n",
       "4   3600       small              2008  manual     69  fabia    90000   \n",
       "\n",
       "   fueltype       brand notrepaired  \n",
       "0    petrol  volkswagen         NaN  \n",
       "1  gasoline        audi         yes  \n",
       "2  gasoline        jeep         NaN  \n",
       "3    petrol  volkswagen          no  \n",
       "4  gasoline       skoda          no  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Todas las columnas minusculas\n",
    "df.columns = df.columns.str.lower()\n",
    "columnas_inecesarias = ['datecrawled', 'registrationmonth', 'datecreated', 'numberofpictures', 'postalcode', 'lastseen']\n",
    "df = df.drop(columnas_inecesarias, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Limpieza de los Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limpieza de los valores incongruentes en la columna de `registrationyear`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1910.0\n"
     ]
    }
   ],
   "source": [
    "# Identificar filas con valores atípicos en 'registrationyear'\n",
    "valores_atipicos = df[(df['registrationyear'] < 1910) | (df['registrationyear'] > 2020)]\n",
    "\n",
    "# Filtrar filas con valores válidos en el rango de años 1910-2020\n",
    "valores_validos = df[(df['registrationyear'] >= 1910) & (df['registrationyear'] <= 2020)]\n",
    "\n",
    "# Iterar sobre las filas con valores atípicos\n",
    "for idx, fila_atipica in valores_atipicos.iterrows():\n",
    "    # Filtrar filas con características similares a la fila atípica\n",
    "    filas_similares = valores_validos[\n",
    "        (valores_validos['brand'] == fila_atipica['brand']) &\n",
    "        (valores_validos['model'] == fila_atipica['model'])       \n",
    "    ]\n",
    "    # Calcular la mediana de 'registrationyear' para filas similares\n",
    "    mediana_similares = filas_similares['registrationyear'].median()\n",
    "    # Imputar la mediana como el nuevo valor para la fila atípica\n",
    "    df.loc[idx, 'registrationyear'] = mediana_similares\n",
    "\n",
    "# Verificar que el cambio se haya aplicado correctamente\n",
    "print(df['registrationyear'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limpieza de los datos faltantes en las columnas `vehicletype, gearbox, model, fueltype y notrepaired`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de columnas con datos faltantes\n",
    "columnas_faltantes = ['vehicletype', 'gearbox', 'model', 'fueltype', 'notrepaired']\n",
    "\n",
    "# Itera sobre cada columna\n",
    "for columna in columnas_faltantes:\n",
    "    # Calcula la moda de la columna dentro de cada grupo definido por las otras columnas\n",
    "    moda_condicionada = df.groupby(['price', 'power', 'gearbox', 'fueltype'])[columna].apply(lambda x: x.mode().iloc[0] if not x.mode().empty else 'unknown')\n",
    "    \n",
    "    # Rellena los valores faltantes en la columna utilizando la moda condicionada\n",
    "    for idx, row in df[df[columna].isnull()].iterrows():\n",
    "        condiciones = (row['price'], row['gearbox'], row['fueltype'], row['power'])\n",
    "        df.loc[idx, columna] = moda_condicionada.get(condiciones, 'unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limpieza de los valores incongruentes en la columna `price`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800.0\n"
     ]
    }
   ],
   "source": [
    "# Identificar filas con valores atípicos en 'price'\n",
    "valores_atipicos_price = df[df['price'] < 800]\n",
    "\n",
    "# Filtrar filas con valores válidos en 'price'\n",
    "valores_validos_price = df[df['price'] >= 800]\n",
    "\n",
    "# Iterar sobre las filas con valores atípicos en 'price'\n",
    "for idx, fila_atipica_price in valores_atipicos_price.iterrows():\n",
    "    # Filtrar filas con características similares a la fila atípica en otras columnas\n",
    "    filas_similares_price = valores_validos_price[\n",
    "        (valores_validos_price['brand'] == fila_atipica_price['brand']) &\n",
    "        (valores_validos_price['model'] == fila_atipica_price['model']) \n",
    "        # Agrega más condiciones si es necesario para reflejar las características relevantes\n",
    "    ]\n",
    "    # Calcular la mediana de 'price' para filas similares\n",
    "    mediana_similares_price = filas_similares_price['price'].median()\n",
    "    # Imputar la mediana como el nuevo valor para la fila atípica en 'price'\n",
    "    df.loc[idx, 'price'] = mediana_similares_price\n",
    "\n",
    "# Verificar que el cambio se haya aplicado correctamente\n",
    "print(df['price'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utilizaremos describe para poder ver que nuestros datos sean congruentes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               price  registrationyear          power        mileage\n",
      "count  354368.000000     354294.000000  354369.000000  354369.000000\n",
      "mean     4842.848546       2003.084077     110.094337  128211.172535\n",
      "std      4257.820184          7.536162     189.850405   37905.341530\n",
      "min       800.000000       1910.000000       0.000000    5000.000000\n",
      "25%      1800.000000       1999.000000      69.000000  125000.000000\n",
      "50%      3200.000000       2003.000000     105.000000  150000.000000\n",
      "75%      6490.000000       2008.000000     143.000000  150000.000000\n",
      "max     20000.000000       2019.000000   20000.000000  150000.000000\n"
     ]
    }
   ],
   "source": [
    "# Obtener las estadisticas descriptivas\n",
    "df_stats = df.describe()\n",
    "df = df.dropna()\n",
    "# Mostras las estadisticas\n",
    "print(df_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Preparación de los datos para los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definimos nuestra variable X para las caracteristicas y nuestra variable y como objetivo que es la columna `price`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en características y objetivo\n",
    "X = df.drop('price', axis=1)\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento para ML\n",
    "columnas_numericas = X.select_dtypes(include=['int', 'float']).columns\n",
    "columnas_categoricas = X.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dividimos nuestro conjunto de datos en 60 para el entrenamiento, 20 para la prueba y 20 para la validación.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_valid, y_test, y_valid = train_test_split(X, y, test_size=0.5, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entrenaremos un modelo de Regresion Lineal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 2820.6994825761685\n"
     ]
    }
   ],
   "source": [
    "# Crear transformadores para preprocesamiento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), columnas_numericas),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), columnas_categoricas)\n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regressor', LinearRegression())])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(\"Root Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entrenaremos un modelo de Bosque de Regresion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 2091.565397840245\n",
      "Mejores parámetros encontrados: {'regressor__max_depth': 8, 'regressor__n_estimators': 80}\n",
      "Root Mean Squared Error del mejor modelo: 2088.585375819942\n",
      "Tiempo de búsqueda de cuadrícula: 1776.6908972263336 segundos\n",
      "Velocidad de predicción: 9.114696620207444e-06 segundos por instancia\n"
     ]
    }
   ],
   "source": [
    "# Preprocesar los datos antes de dividirlos\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), columnas_numericas),\n",
    "        ('cat', OneHotEncoder(), columnas_categoricas)\n",
    "    ])\n",
    "\n",
    "# Crear el pipeline de preprocesamiento y modelo\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regressor', RandomForestRegressor())])  \n",
    "\n",
    "# Obtener los datos\n",
    "X = df.drop(columns=['price'])  # Features\n",
    "y = df['price']  # Target variable\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definir la cuadrícula de parámetros a buscar\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [20, 40, 80],  # Número de árboles en el bosque\n",
    "    'regressor__max_depth': [2, 4, 8],  # Profundidad máxima de los árboles\n",
    "}\n",
    "\n",
    "# Realizar búsqueda de cuadrícula\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_root_mean_squared_error')\n",
    "inicio_busqueda = time.time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "fin_busqueda = time.time()\n",
    "tiempo_busqueda = fin_busqueda - inicio_busqueda\n",
    "\n",
    "# Obtener el mejor modelo\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "\n",
    "# Medir tiempo de predicción\n",
    "inicio_prediccion = time.time()\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "fin_prediccion = time.time()\n",
    "tiempo_prediccion = fin_prediccion - inicio_prediccion\n",
    "\n",
    "# Calcular el RMSE\n",
    "mse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(\"Root Mean Squared Error:\", mse)\n",
    "\n",
    "# Imprimir los mejores parámetros y el RMSE\n",
    "print(\"Mejores parámetros encontrados:\", grid_search.best_params_)\n",
    "print(\"Root Mean Squared Error del mejor modelo:\", -grid_search.best_score_) \n",
    "\n",
    "print(\"Tiempo de búsqueda de cuadrícula:\", tiempo_busqueda, \"segundos\")\n",
    "print(\"Velocidad de predicción:\", tiempo_prediccion / len(y_test), \"segundos por instancia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entrenaremos un Modelo LGBMRegressor.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.089047 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Root Mean Squared Error: 1765.7688444401801\n",
      "Tiempo de entrenamiento: 10.144435167312622 segundos\n",
      "Velocidad de predicción: 3.113512662513608e-05 segundos por instancia\n"
     ]
    }
   ],
   "source": [
    "# Crear transformadores para preprocesamiento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), columnas_numericas),\n",
    "        ('cat', OneHotEncoder(), columnas_categoricas)\n",
    "    ])\n",
    "\n",
    "# Crear el pipeline de preprocesamiento y modelo\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regressor', lgb.LGBMRegressor(**params))])\n",
    "\n",
    "# Medir tiempo de entrenamiento\n",
    "inicio_entrenamiento = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "fin_entrenamiento = time.time()\n",
    "tiempo_entrenamiento = fin_entrenamiento - inicio_entrenamiento\n",
    "\n",
    "# Medir tiempo de predicción\n",
    "inicio_prediccion = time.time()\n",
    "y_pred = pipeline.predict(X_valid)\n",
    "fin_prediccion = time.time()\n",
    "tiempo_prediccion = fin_prediccion - inicio_prediccion\n",
    "\n",
    "\n",
    "# Entrenar el pipeline con los datos de entrenamiento\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones con el conjunto de prueba\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "mse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(\"Root Mean Squared Error:\", mse)\n",
    "\n",
    "# Imprimir velocidad de predicción y tiempo de entrenamiento\n",
    "print(\"Tiempo de entrenamiento:\", tiempo_entrenamiento, \"segundos\")\n",
    "print(\"Velocidad de predicción:\", tiempo_prediccion / len(y_test), \"segundos por instancia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entrenaremos un modelo de CatBoostRegressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 3992.9183177\ttotal: 99.6ms\tremaining: 9.86s\n",
      "1:\tlearn: 3775.5681707\ttotal: 133ms\tremaining: 6.5s\n",
      "2:\tlearn: 3581.9663799\ttotal: 165ms\tremaining: 5.33s\n",
      "3:\tlearn: 3402.5447368\ttotal: 197ms\tremaining: 4.72s\n",
      "4:\tlearn: 3247.8679759\ttotal: 228ms\tremaining: 4.33s\n",
      "5:\tlearn: 3113.2088405\ttotal: 260ms\tremaining: 4.07s\n",
      "6:\tlearn: 3000.3905913\ttotal: 293ms\tremaining: 3.89s\n",
      "7:\tlearn: 2895.8306931\ttotal: 335ms\tremaining: 3.86s\n",
      "8:\tlearn: 2809.8773865\ttotal: 369ms\tremaining: 3.73s\n",
      "9:\tlearn: 2739.6471163\ttotal: 403ms\tremaining: 3.62s\n",
      "10:\tlearn: 2670.0548735\ttotal: 434ms\tremaining: 3.51s\n",
      "11:\tlearn: 2612.0556889\ttotal: 465ms\tremaining: 3.41s\n",
      "12:\tlearn: 2563.8957663\ttotal: 496ms\tremaining: 3.32s\n",
      "13:\tlearn: 2522.1139796\ttotal: 527ms\tremaining: 3.24s\n",
      "14:\tlearn: 2486.8600543\ttotal: 559ms\tremaining: 3.17s\n",
      "15:\tlearn: 2452.8765142\ttotal: 591ms\tremaining: 3.1s\n",
      "16:\tlearn: 2426.0636718\ttotal: 622ms\tremaining: 3.04s\n",
      "17:\tlearn: 2401.1095329\ttotal: 652ms\tremaining: 2.97s\n",
      "18:\tlearn: 2379.7007551\ttotal: 684ms\tremaining: 2.91s\n",
      "19:\tlearn: 2361.5390114\ttotal: 716ms\tremaining: 2.86s\n",
      "20:\tlearn: 2346.0686056\ttotal: 746ms\tremaining: 2.81s\n",
      "21:\tlearn: 2331.2079821\ttotal: 778ms\tremaining: 2.76s\n",
      "22:\tlearn: 2320.3282895\ttotal: 810ms\tremaining: 2.71s\n",
      "23:\tlearn: 2309.0473011\ttotal: 845ms\tremaining: 2.68s\n",
      "24:\tlearn: 2299.7290600\ttotal: 878ms\tremaining: 2.63s\n",
      "25:\tlearn: 2289.7090546\ttotal: 908ms\tremaining: 2.58s\n",
      "26:\tlearn: 2281.4220763\ttotal: 938ms\tremaining: 2.54s\n",
      "27:\tlearn: 2274.8271311\ttotal: 967ms\tremaining: 2.49s\n",
      "28:\tlearn: 2269.2111243\ttotal: 998ms\tremaining: 2.44s\n",
      "29:\tlearn: 2263.7381094\ttotal: 1.03s\tremaining: 2.4s\n",
      "30:\tlearn: 2258.3322805\ttotal: 1.06s\tremaining: 2.36s\n",
      "31:\tlearn: 2253.5046970\ttotal: 1.09s\tremaining: 2.32s\n",
      "32:\tlearn: 2249.4644521\ttotal: 1.12s\tremaining: 2.28s\n",
      "33:\tlearn: 2245.2212944\ttotal: 1.15s\tremaining: 2.24s\n",
      "34:\tlearn: 2241.3507789\ttotal: 1.18s\tremaining: 2.19s\n",
      "35:\tlearn: 2237.8138786\ttotal: 1.21s\tremaining: 2.16s\n",
      "36:\tlearn: 2234.7974959\ttotal: 1.25s\tremaining: 2.13s\n",
      "37:\tlearn: 2231.7411866\ttotal: 1.28s\tremaining: 2.09s\n",
      "38:\tlearn: 2228.9997035\ttotal: 1.31s\tremaining: 2.05s\n",
      "39:\tlearn: 2226.8791378\ttotal: 1.34s\tremaining: 2.01s\n",
      "40:\tlearn: 2224.5654017\ttotal: 1.37s\tremaining: 1.97s\n",
      "41:\tlearn: 2222.0140855\ttotal: 1.4s\tremaining: 1.93s\n",
      "42:\tlearn: 2219.3973958\ttotal: 1.43s\tremaining: 1.9s\n",
      "43:\tlearn: 2217.3067590\ttotal: 1.47s\tremaining: 1.86s\n",
      "44:\tlearn: 2215.7172164\ttotal: 1.5s\tremaining: 1.83s\n",
      "45:\tlearn: 2214.0281792\ttotal: 1.53s\tremaining: 1.79s\n",
      "46:\tlearn: 2212.7064345\ttotal: 1.56s\tremaining: 1.75s\n",
      "47:\tlearn: 2211.0005547\ttotal: 1.59s\tremaining: 1.72s\n",
      "48:\tlearn: 2209.8489913\ttotal: 1.62s\tremaining: 1.68s\n",
      "49:\tlearn: 2208.3727753\ttotal: 1.65s\tremaining: 1.65s\n",
      "50:\tlearn: 2206.6624207\ttotal: 1.68s\tremaining: 1.61s\n",
      "51:\tlearn: 2205.8254372\ttotal: 1.71s\tremaining: 1.57s\n",
      "52:\tlearn: 2204.4112254\ttotal: 1.74s\tremaining: 1.54s\n",
      "53:\tlearn: 2203.5473216\ttotal: 1.77s\tremaining: 1.51s\n",
      "54:\tlearn: 2202.1878936\ttotal: 1.8s\tremaining: 1.47s\n",
      "55:\tlearn: 2201.5890018\ttotal: 1.83s\tremaining: 1.44s\n",
      "56:\tlearn: 2200.4544935\ttotal: 1.86s\tremaining: 1.4s\n",
      "57:\tlearn: 2199.9095196\ttotal: 1.89s\tremaining: 1.37s\n",
      "58:\tlearn: 2199.1538645\ttotal: 1.92s\tremaining: 1.34s\n",
      "59:\tlearn: 2198.6498386\ttotal: 1.95s\tremaining: 1.3s\n",
      "60:\tlearn: 2197.6334511\ttotal: 1.98s\tremaining: 1.27s\n",
      "61:\tlearn: 2196.5422612\ttotal: 2.01s\tremaining: 1.23s\n",
      "62:\tlearn: 2196.0673175\ttotal: 2.04s\tremaining: 1.2s\n",
      "63:\tlearn: 2195.1338331\ttotal: 2.07s\tremaining: 1.17s\n",
      "64:\tlearn: 2194.2591819\ttotal: 2.1s\tremaining: 1.13s\n",
      "65:\tlearn: 2193.7821080\ttotal: 2.14s\tremaining: 1.1s\n",
      "66:\tlearn: 2192.8485904\ttotal: 2.17s\tremaining: 1.07s\n",
      "67:\tlearn: 2192.2824025\ttotal: 2.2s\tremaining: 1.03s\n",
      "68:\tlearn: 2191.6647204\ttotal: 2.23s\tremaining: 1s\n",
      "69:\tlearn: 2190.2180202\ttotal: 2.26s\tremaining: 969ms\n",
      "70:\tlearn: 2189.7001582\ttotal: 2.29s\tremaining: 936ms\n",
      "71:\tlearn: 2189.3320141\ttotal: 2.32s\tremaining: 904ms\n",
      "72:\tlearn: 2189.1247310\ttotal: 2.35s\tremaining: 870ms\n",
      "73:\tlearn: 2188.5751761\ttotal: 2.38s\tremaining: 837ms\n",
      "74:\tlearn: 2187.8286482\ttotal: 2.41s\tremaining: 805ms\n",
      "75:\tlearn: 2187.4673722\ttotal: 2.44s\tremaining: 771ms\n",
      "76:\tlearn: 2187.0318013\ttotal: 2.47s\tremaining: 739ms\n",
      "77:\tlearn: 2186.7809590\ttotal: 2.5s\tremaining: 706ms\n",
      "78:\tlearn: 2186.0382915\ttotal: 2.54s\tremaining: 674ms\n",
      "79:\tlearn: 2185.2466624\ttotal: 2.57s\tremaining: 643ms\n",
      "80:\tlearn: 2184.7402804\ttotal: 2.6s\tremaining: 611ms\n",
      "81:\tlearn: 2184.4012909\ttotal: 2.63s\tremaining: 578ms\n",
      "82:\tlearn: 2183.4708466\ttotal: 2.67s\tremaining: 546ms\n",
      "83:\tlearn: 2182.8388894\ttotal: 2.7s\tremaining: 514ms\n",
      "84:\tlearn: 2182.3999763\ttotal: 2.73s\tremaining: 482ms\n",
      "85:\tlearn: 2181.5736490\ttotal: 2.76s\tremaining: 450ms\n",
      "86:\tlearn: 2180.9515639\ttotal: 2.8s\tremaining: 418ms\n",
      "87:\tlearn: 2180.4910985\ttotal: 2.83s\tremaining: 385ms\n",
      "88:\tlearn: 2179.9228844\ttotal: 2.86s\tremaining: 353ms\n",
      "89:\tlearn: 2179.6005207\ttotal: 2.89s\tremaining: 321ms\n",
      "90:\tlearn: 2179.1172551\ttotal: 2.92s\tremaining: 288ms\n",
      "91:\tlearn: 2178.4609205\ttotal: 2.95s\tremaining: 256ms\n",
      "92:\tlearn: 2177.9095054\ttotal: 2.98s\tremaining: 224ms\n",
      "93:\tlearn: 2177.4668788\ttotal: 3.01s\tremaining: 192ms\n",
      "94:\tlearn: 2177.0524566\ttotal: 3.04s\tremaining: 160ms\n",
      "95:\tlearn: 2176.5303596\ttotal: 3.07s\tremaining: 128ms\n",
      "96:\tlearn: 2176.1444587\ttotal: 3.1s\tremaining: 96ms\n",
      "97:\tlearn: 2175.0086601\ttotal: 3.13s\tremaining: 64ms\n",
      "98:\tlearn: 2174.7557359\ttotal: 3.16s\tremaining: 32ms\n",
      "99:\tlearn: 2174.5166273\ttotal: 3.19s\tremaining: 0us\n",
      "Root Mean Squared Error: 2177.8778652782735\n",
      "Tiempo de entrenamiento: 3.53338885307312 segundos\n",
      "Velocidad de predicción: 2.838557395820066e-07 segundos por instancia\n"
     ]
    }
   ],
   "source": [
    "# Crear transformadores para preprocesamiento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), columnas_numericas),\n",
    "        # No necesitamos tratar las variables categóricas previamente para CatBoost\n",
    "    ])\n",
    "\n",
    "# Crear el pipeline de preprocesamiento y modelo\n",
    "params = {\n",
    "    'objective': 'RMSE',  # Usamos 'RMSE' como métrica\n",
    "    'num_boost_round': 100,  # Número máximo de iteraciones\n",
    "    'learning_rate': 0.1,\n",
    "}\n",
    "\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regressor', CatBoostRegressor(**params))])\n",
    "\n",
    "# Medir tiempo de entrenamiento\n",
    "inicio_entrenamiento = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "fin_entrenamiento = time.time()\n",
    "tiempo_entrenamiento = fin_entrenamiento - inicio_entrenamiento\n",
    "\n",
    "# Medir tiempo de predicción\n",
    "inicio_prediccion = time.time()\n",
    "y_pred = pipeline.predict(X_test)\n",
    "fin_prediccion = time.time()\n",
    "tiempo_prediccion = fin_prediccion - inicio_prediccion\n",
    "\n",
    "# Calcular el RMSE\n",
    "mse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(\"Root Mean Squared Error:\", mse)\n",
    "\n",
    "# Imprimir velocidad de predicción y tiempo de entrenamiento\n",
    "print(\"Tiempo de entrenamiento:\", tiempo_entrenamiento, \"segundos\")\n",
    "print(\"Velocidad de predicción:\", tiempo_prediccion / len(y_test), \"segundos por instancia\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entrenaremos un modelo XGBRegressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 1647.2193735819444\n",
      "Tiempo de entrenamiento: 27.830370903015137 segundos\n",
      "Velocidad de predicción: 9.318796879038782e-06 segundos por instancia\n"
     ]
    }
   ],
   "source": [
    "# Crear transformadores para preprocesamiento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), columnas_numericas),\n",
    "        ('cat', OneHotEncoder(), columnas_categoricas)\n",
    "    ])\n",
    "\n",
    "# Crear el pipeline de preprocesamiento y modelo\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regressor', XGBRegressor(objective='reg:squarederror'))])  # 'reg:squarederror' para regresión\n",
    "\n",
    "# Medir tiempo de entrenamiento\n",
    "inicio_entrenamiento = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "fin_entrenamiento = time.time()\n",
    "tiempo_entrenamiento = fin_entrenamiento - inicio_entrenamiento\n",
    "\n",
    "# Medir tiempo de predicción\n",
    "inicio_prediccion = time.time()\n",
    "y_pred = pipeline.predict(X_test)\n",
    "fin_prediccion = time.time()\n",
    "tiempo_prediccion = fin_prediccion - inicio_prediccion\n",
    "\n",
    "# Calcular el RMSE\n",
    "mse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(\"Root Mean Squared Error:\", mse)\n",
    "\n",
    "# Imprimir velocidad de predicción y tiempo de entrenamiento\n",
    "print(\"Tiempo de entrenamiento:\", tiempo_entrenamiento, \"segundos\")\n",
    "print(\"Velocidad de predicción:\", tiempo_prediccion / len(y_test), \"segundos por instancia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>RMSE Testeo</th>\n",
       "      <th>Tiempo de Predicción (s)</th>\n",
       "      <th>Tiempo de Entrenamiento (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1647.22</td>\n",
       "      <td>9.32</td>\n",
       "      <td>27.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>1765.77</td>\n",
       "      <td>3.11</td>\n",
       "      <td>10.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>2091.57</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1776.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>2177.88</td>\n",
       "      <td>2.84</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Modelo  RMSE Testeo  Tiempo de Predicción (s)  \\\n",
       "0        XGBoost      1647.22                      9.32   \n",
       "1       LightGBM      1765.77                      3.11   \n",
       "2  Random Forest      2091.57                      9.11   \n",
       "3       CatBoost      2177.88                      2.84   \n",
       "\n",
       "   Tiempo de Entrenamiento (s)  \n",
       "0                        27.83  \n",
       "1                        10.14  \n",
       "2                      1776.70  \n",
       "3                         3.53  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Definir los resultados de prueba y entrenamiento de cada modelo\n",
    "resultados = {\n",
    "    'Modelo': ['XGBoost','LightGBM','Random Forest','CatBoost'],\n",
    "    'RMSE Testeo': [1647.22, 1765.77, 2091.57, 2177.88],  # RMSE obtenido en prueba para cada modelo\n",
    "    'Tiempo de Predicción (s)': [9.32, 3.11, 9.11,2.84],  # Tiempo de predicción promedio por instancia en segundos\n",
    "    'Tiempo de Entrenamiento (s)': [27.83, 10.14,1776.70,3.53]  # Tiempo de entrenamiento en segundos para cada modelo\n",
    "}\n",
    "\n",
    "# Crear DataFrame con los resultados\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "# Mostrar la tabla\n",
    "display(df_resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 1703.730840477373\n",
      "Tiempo de entrenamiento: 27.944493532180786 segundos\n",
      "Velocidad de predicción: 9.02035171944469e-06 segundos por instancia\n"
     ]
    }
   ],
   "source": [
    "# Numero Uno Mejor Modelo Ahora con el conjunto de Validación\n",
    "\n",
    "# Crear transformadores para preprocesamiento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), columnas_numericas),\n",
    "        ('cat', OneHotEncoder(), columnas_categoricas)\n",
    "    ])\n",
    "\n",
    "# Crear el pipeline de preprocesamiento y modelo\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regressor', XGBRegressor(objective='reg:squarederror'))])  # 'reg:squarederror' para regresión\n",
    "\n",
    "# Medir tiempo de entrenamiento\n",
    "inicio_entrenamiento = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "fin_entrenamiento = time.time()\n",
    "tiempo_entrenamiento = fin_entrenamiento - inicio_entrenamiento\n",
    "\n",
    "# Medir tiempo de predicción\n",
    "inicio_prediccion = time.time()\n",
    "y_pred = pipeline.predict(X_valid)\n",
    "fin_prediccion = time.time()\n",
    "tiempo_prediccion = fin_prediccion - inicio_prediccion\n",
    "\n",
    "# Calcular el RMSE\n",
    "mse_valid = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "print(\"Root Mean Squared Error:\", mse_valid)\n",
    "\n",
    "# Imprimir velocidad de predicción y tiempo de entrenamiento\n",
    "print(\"Tiempo de entrenamiento:\", tiempo_entrenamiento, \"segundos\")\n",
    "print(\"Velocidad de predicción:\", tiempo_prediccion / len(y_test), \"segundos por instancia\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBSERVACIONES:** Escogimos este modelo como el mejor de los anteriores para poner aprueba con nuestro conjunto de validación ya que a pesar de que es un poco tardado en su tiempo de entrenamiento y de predicción, posee el menor valor rmse aunque en este momento podemos ver que con el conjunto de validación su rmse aumento casi 200 aunqus su tiempo para entrenar y predecir disminuyo un poco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "Root Mean Squared Error: 1647.2193735819444\n",
      "Tiempo de entrenamiento: 7.505645751953125 segundos\n",
      "Velocidad de predicción: 1.1985730744260957e-05 segundos por instancia\n"
     ]
    }
   ],
   "source": [
    "# Segundo Mejor modelo con el Conjunto de Validación\n",
    "\n",
    "# Crear transformadores para preprocesamiento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), columnas_numericas),\n",
    "        ('cat', OneHotEncoder(), columnas_categoricas)\n",
    "    ])\n",
    "\n",
    "# Crear el pipeline de preprocesamiento y modelo\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regressor', lgb.LGBMRegressor(**params))])\n",
    "\n",
    "# Medir tiempo de entrenamiento\n",
    "inicio_entrenamiento = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "fin_entrenamiento = time.time()\n",
    "tiempo_entrenamiento = fin_entrenamiento - inicio_entrenamiento\n",
    "\n",
    "# Medir tiempo de predicción\n",
    "inicio_prediccion = time.time()\n",
    "y_pred = pipeline.predict(X_valid)\n",
    "fin_prediccion = time.time()\n",
    "tiempo_prediccion = fin_prediccion - inicio_prediccion\n",
    "\n",
    "# Entrenar el pipeline con los datos de entrenamiento\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones con el conjunto de prueba\n",
    "y_pred = pipeline.predict(X_valid)\n",
    "\n",
    "# Evaluar el modelo\n",
    "mse_valid = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "print(\"Root Mean Squared Error:\", mse)\n",
    "\n",
    "# Imprimir velocidad de predicción y tiempo de entrenamiento\n",
    "print(\"Tiempo de entrenamiento:\", tiempo_entrenamiento, \"segundos\")\n",
    "print(\"Velocidad de predicción:\", tiempo_prediccion / len(y_test), \"segundos por instancia\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBSERVACIONES:** Este fue uno de los modelos que menos tardo en entrenarse y para predecir y fue el segundo con un mejor valor rmse, algo interesante que podemos ver es que en este momento este modelo `LGBMRegressor` obtuvo un mejor valor rmse que el modelo XGBRegressor y ademas tiene un mejor tiempo, por lo tanto hasta este momento este es nuestro mejor modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 2067.538706726016\n",
      "Tiempo de entrenamiento: 179.73693752288818 segundos\n",
      "Velocidad de predicción: 2.3031351159490013e-05 segundos por instancia\n"
     ]
    }
   ],
   "source": [
    "# Tercer Mejor modelo ahora con el Conjunto de Validación\n",
    "\n",
    "# Preprocesar los datos antes de dividirlos\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), columnas_numericas),\n",
    "        ('cat', OneHotEncoder(), columnas_categoricas)\n",
    "    ])\n",
    "\n",
    "# Crear el pipeline de preprocesamiento y modelo con los mejores parámetros\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regressor', RandomForestRegressor(max_depth=8, n_estimators=80))])  \n",
    "\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "inicio_entrenamiento = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "fin_entrenamiento = time.time()\n",
    "tiempo_entrenamiento = fin_entrenamiento - inicio_entrenamiento\n",
    "\n",
    "# Predecir con el modelo entrenado\n",
    "inicio_prediccion = time.time()\n",
    "y_pred = pipeline.predict(X_valid)\n",
    "fin_prediccion = time.time()\n",
    "tiempo_prediccion = fin_prediccion - inicio_prediccion\n",
    "\n",
    "# Calcular el RMSE\n",
    "mse_valid = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "print(\"Root Mean Squared Error:\", mse_valid)\n",
    "\n",
    "# Imprimir el tiempo de entrenamiento y predicción\n",
    "print(\"Tiempo de entrenamiento:\", tiempo_entrenamiento, \"segundos\")\n",
    "print(\"Velocidad de predicción:\", tiempo_prediccion / len(y_test), \"segundos por instancia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBSERVACIONES:** Escogimos este modelo para probar con nuestro conjunto de validación debido a que era el tercer modelo con mejor valor rmse aunque el unico detalle con este modelo es que es el mas lento para entrenarse al haber durado mucho mas que los demas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusión\n",
    "\n",
    "Para concluir este proyecto me gustaria destacar tres puntos principales que son los siguientes:\n",
    "1. Nuesto mejor modelo es el LGBM Regressor con un RMSE de 1647 en el conjunto de validación y un tiempo de entrenamiento de aproximadamente 7.5 segundos y 1 segundo de velocidad de predicción.\n",
    "2. Siempre es bueno revisar los modelos con el conjunto de validación y testeo para decidir el mejor y no basarnos en solo una prueba con un solo conjunto de datos.\n",
    "3. Es muy imporante limpiar nuestro conjunto de datos de una forma adecuada y no tener valores nan para poder trabajar con nuestros modelos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
